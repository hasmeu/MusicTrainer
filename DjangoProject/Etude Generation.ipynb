{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Install a potentially more compatible version of transformers and datasets\n",
    "# Install a potentially more compatible version of transformers, datasets, and accelerate\n",
    "!pip install datasets==2.16.1 transformers==4.38.0 peft==0.8.2 accelerate==0.27.2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:04:00.655188Z",
     "start_time": "2025-07-02T23:01:43.143464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load your dataset with predefined splits\n",
    "dataset = load_dataset(\"sander-wood/melodyhub\")\n",
    "\n",
    "# Assuming the dataset has 'train' and 'validation' splits\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "\n",
    "# You can optionally split the validation set to create a test set\n",
    "# For example, split the validation set into new validation and test sets\n",
    "# This approach keeps the original train set intact.\n",
    "validation_test_split = validation_dataset.train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "new_validation_dataset = validation_test_split['train']  # This will be the new validation set\n",
    "test_dataset = validation_test_split['test']      # This will be your test set\n",
    "\n",
    "print(\"Original Train Set:\", train_dataset)\n",
    "print(\"New Validation Set:\", new_validation_dataset)\n",
    "print(\"Test Set:\", test_dataset)"
   ],
   "id": "f2561809d5eb9bdb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smith\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 8.40kB [00:00, 3.77MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 649M/649M [01:59<00:00, 5.44MB/s] \n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.93M/7.93M [00:00<00:00, 13.2MB/s]\n",
      "Generating train split: 1055046 examples [00:01, 778924.20 examples/s]\n",
      "Generating validation split: 12701 examples [00:00, 587444.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Set: Dataset({\n",
      "    features: ['dataset', 'task', 'input', 'output'],\n",
      "    num_rows: 1055046\n",
      "})\n",
      "New Validation Set: Dataset({\n",
      "    features: ['dataset', 'task', 'input', 'output'],\n",
      "    num_rows: 6350\n",
      "})\n",
      "Test Set: Dataset({\n",
      "    features: ['dataset', 'task', 'input', 'output'],\n",
      "    num_rows: 6351\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:15:44.392002Z",
     "start_time": "2025-07-02T23:04:27.776447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize a tokenizer\n",
    "# You can choose a different pre-trained tokenizer if it suits your needs better\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Now you can use this tokenizer to process your datasets\n",
    "# For example, tokenizing the 'text' column (assuming your dataset has a 'text' column)\n",
    "def tokenize_function(examples):\n",
    "    # Assuming the ABC notation is in a column named 'input' based on the error and likely dataset structure\n",
    "    # Original comment said 'text', but the error traceback is using 'input'.\n",
    "    return tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply the tokenization to your datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_new_validation_dataset = new_validation_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"\\nTokenized Datasets:\")\n",
    "print(\"Tokenized Train Set:\", tokenized_train_dataset)\n",
    "print(\"Tokenized New Validation Set:\", tokenized_new_validation_dataset)\n",
    "print(\"Tokenized Test Set:\", tokenized_test_dataset)"
   ],
   "id": "c45aaeab7869687",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smith\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\smith\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smith\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1055046/1055046 [10:59<00:00, 1599.16 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6350/6350 [00:05<00:00, 1246.19 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6351/6351 [00:04<00:00, 1308.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized Datasets:\n",
      "Tokenized Train Set: Dataset({\n",
      "    features: ['dataset', 'task', 'input', 'output', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1055046\n",
      "})\n",
      "Tokenized New Validation Set: Dataset({\n",
      "    features: ['dataset', 'task', 'input', 'output', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 6350\n",
      "})\n",
      "Tokenized Test Set: Dataset({\n",
      "    features: ['dataset', 'task', 'input', 'output', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 6351\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:44:46.254494Z",
     "start_time": "2025-07-02T23:37:21.069429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import hashlib\n",
    "\n",
    "# Improved Memory-efficient label encoder with unknown label handling\n",
    "class RobustLabelEncoder:\n",
    "    def __init__(self, unknown_token=\"<UNK>\"):\n",
    "        self.label_to_int = {}\n",
    "        self.int_to_label = {}\n",
    "        self.next_int = 0\n",
    "        self.unknown_token = unknown_token\n",
    "        self.unknown_id = None\n",
    "\n",
    "    def fit(self, labels):\n",
    "        # Add unknown token first\n",
    "        self.label_to_int[self.unknown_token] = self.next_int\n",
    "        self.int_to_label[self.next_int] = self.unknown_token\n",
    "        self.unknown_id = self.next_int\n",
    "        self.next_int += 1\n",
    "\n",
    "        # Add all unique labels\n",
    "        unique_labels = set(labels)\n",
    "        for label in unique_labels:\n",
    "            if label not in self.label_to_int:\n",
    "                self.label_to_int[label] = self.next_int\n",
    "                self.int_to_label[self.next_int] = label\n",
    "                self.next_int += 1\n",
    "        return self\n",
    "\n",
    "    def transform(self, labels):\n",
    "        # Handle unknown labels gracefully\n",
    "        return [self.label_to_int.get(label, self.unknown_id) for label in labels]\n",
    "\n",
    "    def fit_transform(self, labels):\n",
    "        return self.fit(labels).transform(labels)\n",
    "\n",
    "    def inverse_transform(self, encoded_labels):\n",
    "        return [self.int_to_label.get(encoded, self.unknown_token) for encoded in encoded_labels]\n",
    "\n",
    "# Debug: Check dataset structure first\n",
    "print(\"Checking dataset structure...\")\n",
    "sample = tokenized_train_dataset[0]\n",
    "print(f\"Available columns: {list(sample.keys())}\")\n",
    "\n",
    "# Collect all unique labels from ALL datasets to ensure consistent vocabulary\n",
    "print(\"Collecting all unique labels from all datasets...\")\n",
    "all_train_labels = set(train_dataset['output'])\n",
    "all_validation_labels = set(new_validation_dataset['output'])\n",
    "all_test_labels = set(test_dataset['output'])\n",
    "\n",
    "# Combine all labels to create complete vocabulary\n",
    "all_unique_labels = all_train_labels.union(all_validation_labels).union(all_test_labels)\n",
    "num_labels = len(all_unique_labels) + 1  # +1 for unknown token\n",
    "\n",
    "print(f\"Total unique labels found across all datasets: {len(all_unique_labels)}\")\n",
    "print(f\"Number of labels for model (including UNK): {num_labels}\")\n",
    "\n",
    "# Initialize the robust label encoder\n",
    "label_encoder = RobustLabelEncoder()\n",
    "\n",
    "# Fit the encoder on ALL unique labels from all datasets\n",
    "print(\"Fitting label encoder on complete vocabulary...\")\n",
    "label_encoder.fit(list(all_unique_labels))\n",
    "print(\"Label encoder fitted successfully!\")\n",
    "\n",
    "# Load the model with correct number of labels\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels)\n",
    "\n",
    "# Function to prepare dataset with robust label encoding and error handling\n",
    "def prepare_dataset(example):\n",
    "    # Check if 'output' column exists\n",
    "    if 'output' not in example:\n",
    "        raise KeyError(f\"'output' column not found. Available columns: {list(example.keys())}\")\n",
    "\n",
    "    # Safely encode the label\n",
    "    try:\n",
    "        example['labels'] = label_encoder.transform([example['output']])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding label '{example['output']}': {e}\")\n",
    "        example['labels'] = label_encoder.unknown_id  # Use unknown token ID as fallback\n",
    "\n",
    "    return example\n",
    "\n",
    "# Apply the preparation function to your datasets\n",
    "print(\"Preparing datasets...\")\n",
    "try:\n",
    "    tokenized_train_dataset = tokenized_train_dataset.map(prepare_dataset)\n",
    "    tokenized_new_validation_dataset = tokenized_new_validation_dataset.map(prepare_dataset)\n",
    "    tokenized_test_dataset = tokenized_test_dataset.map(prepare_dataset)\n",
    "    print(\"Datasets prepared successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing datasets: {e}\")\n",
    "    print(\"Attempting to inspect dataset structure...\")\n",
    "\n",
    "    # If there's still an error, let's check the original datasets\n",
    "    print(f\"Original train dataset columns: {train_dataset.column_names}\")\n",
    "    print(f\"Tokenized train dataset columns: {tokenized_train_dataset.column_names}\")\n",
    "\n",
    "    # Check if 'output' exists in original but not in tokenized\n",
    "    if 'output' in train_dataset.column_names and 'output' not in tokenized_train_dataset.column_names:\n",
    "        print(\"'output' column was removed during tokenization. Re-adding it...\")\n",
    "\n",
    "        # Check if 'output' column exists before adding it\n",
    "        if 'output' not in tokenized_train_dataset.column_names:\n",
    "            tokenized_train_dataset = tokenized_train_dataset.add_column('output', train_dataset['output'])\n",
    "\n",
    "        if 'output' not in tokenized_new_validation_dataset.column_names:\n",
    "            tokenized_new_validation_dataset = tokenized_new_validation_dataset.add_column('output', new_validation_dataset['output'])\n",
    "\n",
    "        if 'output' not in tokenized_test_dataset.column_names:\n",
    "            tokenized_test_dataset = tokenized_test_dataset.add_column('output', test_dataset['output'])\n",
    "\n",
    "        # Now try preparing datasets again\n",
    "        tokenized_train_dataset = tokenized_train_dataset.map(prepare_dataset)\n",
    "        tokenized_new_validation_dataset = tokenized_new_validation_dataset.map(prepare_dataset)\n",
    "        tokenized_test_dataset = tokenized_test_dataset.map(prepare_dataset)\n",
    "        print(\"Datasets prepared successfully after re-adding output column!\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=tokenized_train_dataset, # training dataset\n",
    "    eval_dataset=tokenized_new_validation_dataset,  # evaluation dataset\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# You can also evaluate the model after training\n",
    "print(\"Evaluating model...\")\n",
    "results = trainer.evaluate(tokenized_test_dataset)\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(results)"
   ],
   "id": "b7088ae5d1b8ddfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset structure...\n",
      "Available columns: ['input_ids', 'attention_mask', 'labels', 'output']\n",
      "Collecting all unique labels from all datasets...\n",
      "Total unique labels found across all datasets: 848103\n",
      "Number of labels for model (including UNK): 848104\n",
      "Fitting label encoder on complete vocabulary...\n",
      "Label encoder fitted successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1055046/1055046 [01:31<00:00, 11589.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6350/6350 [00:00<00:00, 7047.72 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6351/6351 [00:00<00:00, 7394.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets prepared successfully!\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smith\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='395643' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     4/395643 02:22 < 7805:28:21, 0.01 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 145\u001B[39m\n\u001B[32m    143\u001B[39m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[32m    144\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mStarting training...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m145\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[38;5;66;03m# You can also evaluate the model after training\u001B[39;00m\n\u001B[32m    148\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mEvaluating model...\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1624\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   1622\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   1623\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1624\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1625\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1626\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1627\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1628\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1629\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1961\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   1958\u001B[39m     \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_step_begin(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m   1960\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.accumulate(model):\n\u001B[32m-> \u001B[39m\u001B[32m1961\u001B[39m     tr_loss_step = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1963\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1964\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   1965\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[32m   1966\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   1967\u001B[39m ):\n\u001B[32m   1968\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   1969\u001B[39m     tr_loss += tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2911\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(self, model, inputs)\u001B[39m\n\u001B[32m   2909\u001B[39m         scaled_loss.backward()\n\u001B[32m   2910\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2911\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2913\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach() / \u001B[38;5;28mself\u001B[39m.args.gradient_accumulation_steps\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\accelerate\\accelerator.py:1966\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   1964\u001B[39m     \u001B[38;5;28mself\u001B[39m.scaler.scale(loss).backward(**kwargs)\n\u001B[32m   1965\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1966\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI Music App\\MusicTrainer\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
